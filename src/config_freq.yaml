# Configuration for FREQUENCY-DOMAIN signal convolution experiment
# 
# This config trains a transformer to learn convolution in the frequency domain.
# Here we use an interleaved magnitude/phase representation in the frequency domain.
#
# Hypothesis: Frequency-domain learning should be easier because convolution
# becomes element-wise multiplication (linear operation).

out_dir: ./outputs

# Model architecture
model:
    family: gpt2
    n_dims: 32         # Frequency domain: dimension = 2p (real + imag)
    out_dim: 32        # Output same as input
    n_positions: 101    # Max context length (number of (x,y) pairs)
    n_embd: 256         # Embedding dimension (same as time domain)
    n_layer: 12         # Number of transformer layers (same as time domain)
    n_head: 8          # Number of attention heads (same as time domain)
# model:
#     family: gpt2
#     n_dims: 32        # Time domain: dimension = p
#     out_dim: 32         # Output same as input
#     n_positions: 101    # Max context length (number of (x,y) pairs)
#     n_embd: 64         # Embedding dimension
#     n_layer: 4         # Number of transformer layers
#     n_head: 4           # Number of attention heads

# Training configuration
training:
    # Task: signal convolution
    task: signal_conv
    task_kwargs:
        p: 30                    # Signal period (same as time domain)
        fir_len: 20              # FIR filter length (same as time domain)
        domain: freq             # Frequency domain
        device: cuda
        freq_representation: complex   # use interleaved [|X_k|, arg(X_k)] instead of Re/Im
    
    # Data: signal generation
    data: signal
    data_kwargs:
        p: 30                    # Signal period (same as time domain)
        domain: freq             # Frequency domain
        amp_dist: normal         # Normal distribution for amplitudes
        amp_std: 1.0             # Standard deviation for amplitudes
        num_freqs: 30           # Number of frequency components (harmonics)
        device: cuda
        freq_representation: complex   # generate interleaved [|X_k|, arg(X_k)] inputs
    
    # Training hyperparameters (same as time domain for fair comparison)
    batch_size: 512
    learning_rate: 0.0001
    train_steps: 100001
    
    # Checkpointing
    save_every_steps: 40000       # Save training state every N steps
    keep_every_steps: 10000     # Keep permanent model snapshots every N steps
    
    # Deterministic training pool (same as time domain)
    num_training_examples: None # Fix pool of 10k examples for reproducibility
    
    # Loss function
    loss_space: time            
    
    # Curriculum learning (same as time domain)
    curriculum:
        # Context length curriculum: gradually increase from 5 to 41 examples
        points:
            start: 5             # Start with 5 in-context examples
            end: 55              # End with 41 in-context examples
            inc: 1               # Increment by 1
            interval: 2000       # Every 2000 steps
        
# Weights & Biases logging
wandb:
    project: signal-incontext
    entity: leonkornfeld-uc-berkeley-electrical-engineering-computer         # Change this to your W&B entity
    name: freq_p30_fir5_b512_dec14_18:54
    notes: "Frequency-domain transformer learning convolution with p=30, FIR length=5"
    log_every_steps: 10

# Quick test run flag
test_run: false